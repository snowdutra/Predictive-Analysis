---
title: "Tom Sentiment Lab: Análise de Sentimentos em Tom Sawyer"
author: "Gustavo Dutra"
date: "`r Sys.Date()`"
output:
  pdf_document: default
  word_document: default
---

# Introdução

Este relatório apresenta uma análise de sentimentos do romance "The Adventures of Tom Sawyer", de Mark Twain, utilizando técnicas de text mining com tidytext e tidyverse em R.

# 1. Preparação do Corpus

```{r setup, message=FALSE, warning=FALSE}
library(tidyverse)
library(tidytext)
library(stringr)
library(knitr)
library(ggplot2)
library(textdata)

# Carregar o texto
setwd("C:/Users/gustavo.telles/Documents/GitHub/Predictive-Analysis/tom-sentiment-lab") # nolint
tom_raw <- readLines("C:/Users/gustavo.telles/Documents/GitHub/Predictive-Analysis/tom-sentiment-lab/tom_sawyer.txt", encoding = "UTF-8") # nolint
tom_tbl <- tibble(
  text = tom_raw, # nolint
  linenumber = seq_along(tom_raw)
)
# Detectar capítulos por regex
tom_tbl <- tom_tbl %>%
  mutate(chapter = cumsum(str_detect(text, regex("CHAPTER\\s+[IVXLCDM0-9]+", ignore_case = TRUE)))) # nolint
```

# 2. Tokenização e Limpeza

```{r tokenizacao}
# Tokenização por palavra
tom_words <- tom_tbl %>%
  unnest_tokens(word, text) %>%
  mutate(word = str_to_lower(word)) %>%
  filter(str_detect(word, "^[a-z]+$"))

# Remover stopwords
data("stop_words")
tom_words_nostop <- tom_words %>%
  anti_join(stop_words, by = "word")
```

# 3. Análise de Frequência

```{r frequencia}
# 20 palavras mais frequentes (com stopwords)
top_words <- tom_words %>%
  count(word, sort = TRUE) %>%
  slice_max(n, n = 20)

# 20 palavras mais frequentes (sem stopwords)
top_words_nostop <- tom_words_nostop %>%
  count(word, sort = TRUE) %>%
  slice_max(n, n = 20)

# Visualização
top_words %>% ggplot(aes(reorder(word, n), n)) +
  geom_col() + coord_flip() + labs(title = "Top 20 palavras (com stopwords)")

top_words_nostop %>% ggplot(aes(reorder(word, n), n)) +
  geom_col() + coord_flip() + labs(title = "Top 20 palavras (sem stopwords)")
```

# 4. Análise de Sentimentos

```{r sentimentos}
# Bing
bing <- get_sentiments("bing")
tom_sent_bing <- tom_words %>%
  inner_join(bing, by = "word")

# NRC
nrc <- get_sentiments("nrc")
tom_sent_nrc <- tom_words %>%
  inner_join(nrc, by = "word")

# AFINN
afinn <- get_sentiments("afinn")
tom_sent_afinn <- tom_words %>%
  inner_join(afinn, by = "word")

# Saldo por blocos de 80 linhas
sent_bing_block <- tom_sent_bing %>%
  mutate(block = linenumber %/% 80) %>%
  count(block, sentiment) %>%
  pivot_wider(names_from = sentiment, values_from = n, values_fill = 0) %>%
  mutate(saldo = positive - negative)

# Saldo por capítulo
sent_bing_chapter <- tom_sent_bing %>%
  count(chapter, sentiment) %>%
  pivot_wider(names_from = sentiment, values_from = n, values_fill = 0) %>%
  mutate(saldo = positive - negative)

# Gráficos
sent_bing_block %>%
  filter(!is.na(saldo)) %>%
  ggplot(aes(block, saldo)) +
  geom_col() + labs(title = "Saldo de Sentimento por Bloco (Bing)")

sent_bing_chapter %>%
  filter(!is.na(saldo)) %>%
  ggplot(aes(chapter, saldo)) +
  geom_col() + labs(title = "Saldo de Sentimento por Capítulo (Bing)")

```

```{r grafico_bloco}
sent_bing_block %>%
  filter(!is.na(saldo)) %>%
  ggplot(aes(block, saldo)) +
  geom_col() + labs(title = "Saldo de Sentimento por Bloco (Bing)")
```

```{r grafico_capitulo}
sent_bing_chapter %>%
  filter(!is.na(saldo)) %>%
  ggplot(aes(chapter, saldo)) +
  geom_col() + labs(title = "Saldo de Sentimento por Capítulo (Bing)")
```
```

# 5. Categorias NRC (exemplo: joy)

```{r joy}
joy_words <- tom_sent_nrc %>%
  filter(sentiment == "joy") %>%
  count(word, sort = TRUE) %>%
  slice_max(n, n = 20)

joy_words %>% ggplot(aes(reorder(word, n), n)) +
  geom_col() + coord_flip() + labs(title = "Top 20 palavras de 'joy' (NRC)")
```

# 6. Comparação de Léxicos

```{r comparacao}
# Tabela resumo: saldo de sentimento por capítulo para cada léxico
sent_bing_chapter_resumo <- sent_bing_chapter %>% select(chapter, saldo) %>% rename(saldo_bing = saldo) # nolint

sent_nrc_chapter <- tom_sent_nrc %>%
  filter(sentiment %in% c("positive", "negative")) %>%
  count(chapter, sentiment) %>%
  pivot_wider(names_from = sentiment, values_from = n, values_fill = 0) %>%
  mutate(saldo_nrc = positive - negative)

sent_afinn_chapter <- tom_sent_afinn %>%
  group_by(chapter) %>%
  summarise(saldo_afinn = sum(value, na.rm = TRUE))

# Juntar tudo em uma tabela comparativa
comparativo_chapter <- sent_bing_chapter_resumo %>%
  left_join(sent_nrc_chapter %>% select(chapter, saldo_nrc), by = "chapter") %>% # nolint
  left_join(sent_afinn_chapter, by = "chapter")

# Visualização comparativa dos saldos por capítulo
comparativo_chapter_long <- comparativo_chapter %>%
  pivot_longer(cols = c(saldo_bing, saldo_nrc, saldo_afinn),
               names_to = "lexico", values_to = "saldo")

comparativo_chapter_long %>%
  filter(!is.na(saldo)) %>%
  ggplot(aes(x = chapter, y = saldo, color = lexico)) +
  geom_line(size = 1) +
  labs(title = "Comparação de Saldos de Sentimento por Capítulo",
       x = "Capítulo", y = "Saldo de Sentimento", color = "Léxico")

# Tabela comparativa dos saldos por capítulo
comparativo_chapter %>% head(10) %>% knitr::kable(caption = "Exemplo de tabela comparativa dos 10 primeiros capítulos") # nolint
```

# Discussão Crítica


**Quais capítulos apareceram mais positivos e mais negativos? Isso faz sentido na narrativa?**
Os capítulos mais positivos, segundo os saldos dos léxicos, coincidem com momentos de aventura, amizade e superação, como os capítulos em que Tom e Huck encontram o tesouro ou participam de brincadeiras. Os capítulos mais negativos geralmente envolvem conflitos, punições ou situações de perigo, como o julgamento de Muff Potter ou o desaparecimento de Tom e Becky na caverna. Essa distribuição faz sentido, pois reflete os altos e baixos emocionais da narrativa, alinhando-se com os principais eventos do livro.

**As palavras de joy capturadas pelo NRC representam bem os momentos felizes do livro?**
O NRC identifica palavras associadas à alegria, como "play", "friend", "laugh", "happy" e "freedom", presentes nos trechos de brincadeiras e aventuras. No entanto, pode deixar de captar nuances contextuais, como ironia ou felicidade implícita, e pode incluir palavras em contextos neutros ou negativos, dependendo do uso no texto.

**Entre Bing, NRC e AFINN, qual se mostrou mais adequado para esse texto? Justifique.**
O Bing é mais direto, classificando palavras como positivas ou negativas, facilitando a visualização do saldo emocional por capítulo. O NRC é mais detalhado, permitindo analisar emoções específicas, mas pode gerar sobreposição de sentimentos. O AFINN atribui pontuações de intensidade, útil para medir variações sutis. Para Tom Sawyer, o Bing é mais robusto para visão geral, o NRC é interessante para emoções específicas e o AFINN pode ser menos sensível ao contexto literário.

**A ironia e o humor de Mark Twain foram bem capturados? Cite exemplos onde o algoritmo “erra”.**
Os algoritmos de léxico têm dificuldade em captar ironia e humor. Frases em que Tom faz travessuras ou engana adultos podem ser classificadas como negativas devido ao uso de palavras como "trouble" ou "lie", mesmo que o contexto seja cômico. O sarcasmo nos diálogos também pode ser interpretado erroneamente como sentimento negativo, mostrando que o modelo não entende o contexto narrativo, apenas o significado isolado das palavras.

**Quais seriam as próximas melhorias (ex.: lematização, análise de negação, modelos para português/inglês contemporâneo)?**
- Implementar lematização para agrupar variações de palavras (ex.: "play", "playing", "played").
- Análise de negação para evitar erros em frases como "not happy" ou "never sad".
- Utilizar modelos de sentimentos treinados para literatura ou inglês contemporâneo, que capturam melhor nuances de linguagem.
- Adotar abordagens de aprendizado de máquina ou redes neurais, que consideram contexto e sequência de palavras.
- Adaptar o pipeline para textos em português, caso o corpus seja traduzido ou comparado com obras nacionais.

